{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes our main class: a layer that can .forward() and .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        pass\n",
    "    \n",
    "    def backward(self, input, grad_output):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road ahead\n",
    "\n",
    "We're going to build a neural network that classifies MNIST digits. To do so, we'll need a few building blocks:\n",
    "- Dense layer - a fully-connected layer, $f(X)=X \\cdot W + \\vec{b}$\n",
    "- ReLU layer (or any other nonlinearity you want)\n",
    "- Loss function - crossentropy\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
    "\n",
    "Let's approach them one at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinearity layer\n",
    "\n",
    "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = torch.max(input, torch.tensor([0.], device='cpu'))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "\n",
    "Now let's build something more complicated. Unlike nonlinearity, a dense layer actually has something to learn.\n",
    "\n",
    "A dense layer applies affine transformation. In a vectorized form, it can be described as:\n",
    "$$f(X)= X \\cdot W + \\vec b $$\n",
    "\n",
    "Where \n",
    "* X is an object-feature matrix of shape [batch_size, num_features],\n",
    "* W is a weight matrix [num_features, num_outputs] \n",
    "* and b is a vector of num_outputs biases.\n",
    "\n",
    "Both W and b are initialized during layer creation and updated each time backward is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize weights with small random numbers. We use normal initialization, \n",
    "        # but surely there is something better. Try this once you got it working: http://bit.ly/2vTlmaJ\n",
    "        self.weights = torch.randn(input_units, output_units, device='cpu', requires_grad=True)*0.01\n",
    "        self.biases  = torch.ones(output_units, device='cpu', requires_grad=True)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return torch.matmul(input, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, w_grad, b_grad):\n",
    "        self.weights = self.weights - self.learning_rate * w_grad\n",
    "        self.biases  = self.biases - self.learning_rate * b_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the dense layer\n",
    "\n",
    "Here we have a few tests to make sure your dense layer works properly. You can just run them, get 3 \"well done\"s and forget they ever existed.\n",
    "\n",
    "... or not get 3 \"well done\"s and go fix stuff. If that is the case, here are some tips for you:\n",
    "* Make sure you compute gradients for W and b as __sum of gradients over batch__, not mean over gradients. Grad_output is already divided by batch size.\n",
    "* If you're debugging, try saving gradients in class fields, like \"self.grad_w = grad_w\" or print first 3-5 weights. This helps debugging.\n",
    "* If nothing else helps, try ignoring tests and proceed to network training. If it trains alright, you may be off by something that does not affect network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "l = Dense(3, 4)\n",
    "x = torch.linspace(-1,1,2*3, device='cpu', requires_grad=True).view([2,3])\n",
    "l.forward(x)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
    "\n",
    "If you write down the expression for crossentropy as a function of softmax logits (a), you'll see:\n",
    "\n",
    "$$ loss = - log \\space {e^{a_{correct}} \\over {\\underset i \\sum e^{a_i} } } $$\n",
    "\n",
    "If you take a closer look, ya'll see that it can be rewritten as:\n",
    "\n",
    "$$ loss = - a_{correct} + log {\\underset i \\sum e^{a_i} } $$\n",
    "\n",
    "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
    "* Better numerical stability\n",
    "* Easier to get derivative right\n",
    "* Marginally faster to compute\n",
    "\n",
    "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities.\n",
    "\n",
    "Here you are! We've defined the both loss functions for you so that you could focus on neural network part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full network\n",
    "\n",
    "Now let's combine what we've just built into a working neural network. As we announced, we're gonna use this monster to classify handwritten digits, so let's get them loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3352a52588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=True)\n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train).float().to('cpu')\n",
    "X_train.requires_grad_(True)\n",
    "\n",
    "X_val = torch.from_numpy(X_val).float().to('cpu')\n",
    "X_val.requires_grad_(True)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float().to('cpu')\n",
    "X_test.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Dense(X_train.shape[1], 100))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(100, 200))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(200, 10))\n",
    "\n",
    "# network = []\n",
    "# network.append(Dense(X_train.shape[1], 100))\n",
    "# network.append(ReLU())\n",
    "# network.append(Dense(100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act = forward(network, X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K        = 1\n",
    "# beta     = .1\n",
    "# n_layers = len(network) // 2 + 1\n",
    "# layer    = n_layers\n",
    "\n",
    "# pre_activations     = act[::2] # h\n",
    "# pre_activations_tmp = pre_activations.copy() # h_hat\n",
    "\n",
    "# post_activations     = [X_train[:2]] + act[1::2] # z\n",
    "# layer_post_target    = post_activations.copy() # y_z\n",
    "# post_activations_tmp = post_activations.copy() # z_hat\n",
    "\n",
    "# layer_post_target[-1] = torch.from_numpy(y_train[:2]).long().to('cuda')\n",
    "\n",
    "# print('Before updates ...')\n",
    "# print('Pre activation ', pre_activations)\n",
    "# print('Post activation ', post_activations)\n",
    "\n",
    "# for l in range(len(network) - 1, 0, -2):\n",
    "#     W                   = torch.from_numpy(network[l].weights.cpu().detach().numpy()).to('cuda')\n",
    "#     W.requires_grad_(True)\n",
    "#     b                   = network[l].biases\n",
    "\n",
    "#     z_l_1                = torch.from_numpy(post_activations[layer-1].cpu().detach().numpy()).to('cuda') # z_(l-1)\n",
    "#     z_l_1.requires_grad_(True)  \n",
    "#     z_l                  = torch.matmul(z_l_1, W) + b # z_l\n",
    "    \n",
    "#     print('Layer: ', layer)\n",
    "#     print(layer_post_target[layer - 1])\n",
    "#     print()\n",
    "#     loss = torch.functional.F.nll_loss(z_l, layer_post_target[layer-1])\n",
    "#     loss.backward()\n",
    "\n",
    "#     W_grad = W.grad\n",
    "#     b_grad = b.grad\n",
    "    \n",
    "#     for k in range(K):\n",
    "#         h_l_1  = torch.from_numpy(pre_activations[layer-2].cpu().detach().numpy()).to('cuda')\n",
    "#         h_l_1.requires_grad_(True)\n",
    "\n",
    "#         z_l_1  = network[l-1].forward(h_l_1)\n",
    "#         z_l    = torch.matmul(z_l_1, W) + b\n",
    "        \n",
    "#         loss   = torch.functional.F.nll_loss(z_l, layer_post_target[layer-1])\n",
    "#         loss.backward()\n",
    "\n",
    "#         h_l_1_grad            = h_l_1.grad\n",
    "        \n",
    "#         # updates\n",
    "#         pre_activations[layer-2]  = h_l_1 - beta * h_l_1_grad\n",
    "#         post_activations[layer-1] = network[l-1].forward(pre_activations[layer-1])\n",
    "#         pre_activations[layer-1]  = torch.matmul(z_l_1, W) + b\n",
    "        \n",
    "# #         if layer != n_layers-1:\n",
    "# #             post_activations[layer] = network[l].forward(pre_activations[layer-1])\n",
    "\n",
    "#     layer_post_target[layer-2] = torch.argmax(post_activations[layer-2], dim=-1)\n",
    "    \n",
    "#     layer -= 1\n",
    "\n",
    "# print('\\n\\nAfter updates ...')\n",
    "# print('Pre activation ', pre_activations)\n",
    "# print('Post activation ', post_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(network, X):\n",
    "    activations = []\n",
    "    input       = X\n",
    "    \n",
    "    for layer in network:\n",
    "        input = layer.forward(input)\n",
    "        activations.append(input)\n",
    "        \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network, X):\n",
    "    logits = forward(network, X)[-1]\n",
    "    return logits.cpu().detach().numpy().argmax(axis=-1)\n",
    "\n",
    "def normalize(vec, c):\n",
    "    norm = torch.norm(vec)\n",
    "    \n",
    "    if norm >= c:\n",
    "        return (c * vec) / norm\n",
    "    else:\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LRA-diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network,X,y):\n",
    "    \n",
    "    # parameters\n",
    "    K        = 1\n",
    "    beta     = .001\n",
    "    n_layers = len(network) // 2 + 1\n",
    "    layer    = n_layers\n",
    "    c        = 1\n",
    "    \n",
    "    # forward pass\n",
    "    act = forward(network, X)\n",
    "    \n",
    "    pre_activations      = act[::2] # h\n",
    "    pre_activations_tmp  = pre_activations.copy() # h_hat\n",
    "\n",
    "    post_activations     = [X] + act[1::2] # z\n",
    "    layer_post_target    = post_activations.copy() # y_z\n",
    "    post_activations_tmp = post_activations.copy() # z_hat\n",
    "\n",
    "    layer_post_target[-1] = torch.from_numpy(y).long().to('cpu')\n",
    "    W_grads               = []\n",
    "    b_grads               = []\n",
    "    \n",
    "    for l in range(len(network) - 1, 0, -2):\n",
    "        W                   = torch.from_numpy(network[l].weights.cpu().detach().numpy()).to('cpu')\n",
    "        W.requires_grad_(True)\n",
    "        \n",
    "        b                   = torch.from_numpy(network[l].biases.cpu().detach().numpy()).to('cpu')\n",
    "        b.requires_grad_(True)\n",
    "        \n",
    "        z_l_1                = torch.from_numpy(post_activations[layer-1].cpu().detach().numpy()).to('cpu') # z_(l-1)\n",
    "        z_l_1.requires_grad_(True)  \n",
    "        z_l                  = torch.matmul(z_l_1, W) + b # z_l\n",
    "\n",
    "        loss = torch.functional.F.nll_loss(z_l, layer_post_target[layer-1])\n",
    "        loss.backward()\n",
    "        \n",
    "        w_grad = normalize(W.grad, c)\n",
    "        b_grad = normalize(b.grad, c)\n",
    "\n",
    "        W_grads.append(w_grad)\n",
    "        b_grads.append(b_grad)\n",
    "        \n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "        \n",
    "        for k in range(K):\n",
    "            h_l_1  = torch.from_numpy(pre_activations[layer-2].cpu().detach().numpy()).to('cpu')\n",
    "            h_l_1.requires_grad_(True)\n",
    "\n",
    "            z_l_1  = network[l-1].forward(h_l_1)\n",
    "            z_l    = torch.matmul(z_l_1, W) + b\n",
    "\n",
    "            loss   = torch.functional.F.nll_loss(z_l, layer_post_target[layer-1])\n",
    "            loss.backward()\n",
    "\n",
    "            h_l_1_grad            = h_l_1.grad\n",
    "\n",
    "            # updates\n",
    "            pre_activations[layer-2]  = h_l_1 - beta * h_l_1_grad\n",
    "            post_activations[layer-1] = network[l-1].forward(pre_activations[layer-1])\n",
    "            pre_activations[layer-1]  = torch.matmul(z_l_1, W) + b\n",
    "            \n",
    "            h_l_1.grad.zero_()\n",
    "\n",
    "#             if layer != n_layers-1:\n",
    "#                 post_activations[layer-1] = network[l].forward(pre_activations[layer-1])\n",
    "\n",
    "        layer_post_target[layer-2] = torch.argmax(post_activations[layer-2], dim=-1)\n",
    "        layer -= 1\n",
    "    \n",
    "        \n",
    "    return W_grads[::-1], b_grads[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of tests, we provide you with a training loop that prints training and validation accuracies on every epoch.\n",
    "\n",
    "If your implementation of forward and backward are correct, your accuracy should grow from 90~93% to >97% with the default network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "As usual, we split data into minibatches, feed each such minibatch into the network and update weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Dense(X_train.shape[1], 100))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(100, 200))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(200, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 28/1562 [00:00<00:05, 277.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "tensor([[ 0.0063, -0.0128, -0.0003, -0.0051, -0.0084,  0.0088, -0.0187,  0.0196,\n",
      "         -0.0060,  0.0036],\n",
      "        [-0.0140,  0.0014, -0.0141,  0.0101, -0.0233,  0.0106,  0.0017,  0.0266,\n",
      "         -0.0046, -0.0051],\n",
      "        [-0.0012,  0.0042, -0.0119, -0.0130,  0.0122,  0.0110,  0.0087,  0.0130,\n",
      "         -0.0234, -0.0005],\n",
      "        [-0.0022, -0.0198,  0.0328, -0.0024, -0.0061, -0.0070, -0.0052, -0.0023,\n",
      "          0.0084, -0.0031],\n",
      "        [-0.0012, -0.0069, -0.0010, -0.0191, -0.0121,  0.0033,  0.0098, -0.0018,\n",
      "         -0.0072,  0.0141],\n",
      "        [-0.0049,  0.0289, -0.0095, -0.0084, -0.0067, -0.0014, -0.0092,  0.0048,\n",
      "          0.0093, -0.0123],\n",
      "        [-0.0062,  0.0240,  0.0020,  0.0009, -0.0105,  0.0044, -0.0072,  0.0006,\n",
      "         -0.0133, -0.0068],\n",
      "        [ 0.0093, -0.0122,  0.0029,  0.0113, -0.0015, -0.0059, -0.0147, -0.0041,\n",
      "          0.0223,  0.0071],\n",
      "        [ 0.0025,  0.0122,  0.0033,  0.0138, -0.0024, -0.0101,  0.0086, -0.0075,\n",
      "         -0.0062,  0.0113],\n",
      "        [-0.0002,  0.0113, -0.0045, -0.0015,  0.0013,  0.0019,  0.0026, -0.0152,\n",
      "          0.0050,  0.0039]], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [00:04<00:00, 317.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.1902,  0.1869,  0.1882,  0.1725,  0.1673,  0.1686,  0.1563,  0.2120,\n",
      "          0.1686,  0.1896],\n",
      "        [ 0.3449,  0.4023,  0.3511,  0.3692,  0.3256,  0.3315,  0.3560,  0.4006,\n",
      "          0.3445,  0.3564],\n",
      "        [ 0.2617,  0.2976,  0.2580,  0.2489,  0.2679,  0.2451,  0.2662,  0.2895,\n",
      "          0.2313,  0.2664],\n",
      "        [ 0.1669,  0.1625,  0.2044,  0.1593,  0.1551,  0.1393,  0.1555,  0.1742,\n",
      "          0.1683,  0.1679],\n",
      "        [ 0.3444,  0.3794,  0.3499,  0.3266,  0.3245,  0.3119,  0.3509,  0.3591,\n",
      "          0.3285,  0.3629],\n",
      "        [ 6.7961,  7.8097,  6.8799,  7.0443,  6.6850,  6.2421,  6.8467,  7.1112,\n",
      "          6.7143,  6.8521],\n",
      "        [ 1.8980,  2.1936,  1.9273,  1.9645,  1.8607,  1.7448,  1.9075,  1.9869,\n",
      "          1.8591,  1.9111],\n",
      "        [ 0.1788,  0.1750,  0.1773,  0.1753,  0.1622,  0.1422,  0.1484,  0.1747,\n",
      "          0.1845,  0.1796],\n",
      "        [ 1.9558,  2.2393,  1.9873,  2.0279,  1.9198,  1.7750,  1.9700,  2.0355,\n",
      "          1.9136,  1.9853],\n",
      "        [16.9035, 19.3386, 17.0973, 17.5199, 16.6324, 15.5197, 17.0433, 17.6334,\n",
      "         16.6607, 17.0405]], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 39/1562 [00:00<00:03, 382.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "tensor([[ 0.1902,  0.1869,  0.1882,  0.1725,  0.1673,  0.1686,  0.1563,  0.2120,\n",
      "          0.1686,  0.1896],\n",
      "        [ 0.3449,  0.4023,  0.3511,  0.3692,  0.3256,  0.3315,  0.3560,  0.4006,\n",
      "          0.3445,  0.3564],\n",
      "        [ 0.2617,  0.2976,  0.2580,  0.2489,  0.2679,  0.2451,  0.2662,  0.2895,\n",
      "          0.2313,  0.2664],\n",
      "        [ 0.1669,  0.1625,  0.2044,  0.1593,  0.1551,  0.1393,  0.1555,  0.1742,\n",
      "          0.1683,  0.1679],\n",
      "        [ 0.3444,  0.3794,  0.3499,  0.3266,  0.3245,  0.3119,  0.3509,  0.3591,\n",
      "          0.3285,  0.3629],\n",
      "        [ 6.7961,  7.8097,  6.8799,  7.0443,  6.6850,  6.2421,  6.8467,  7.1112,\n",
      "          6.7143,  6.8521],\n",
      "        [ 1.8980,  2.1936,  1.9273,  1.9645,  1.8607,  1.7448,  1.9075,  1.9869,\n",
      "          1.8591,  1.9111],\n",
      "        [ 0.1788,  0.1750,  0.1773,  0.1753,  0.1622,  0.1422,  0.1484,  0.1747,\n",
      "          0.1845,  0.1796],\n",
      "        [ 1.9558,  2.2393,  1.9873,  2.0279,  1.9198,  1.7750,  1.9700,  2.0355,\n",
      "          1.9136,  1.9853],\n",
      "        [16.9035, 19.3386, 17.0973, 17.5199, 16.6324, 15.5197, 17.0433, 17.6334,\n",
      "         16.6607, 17.0405]], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [00:04<00:00, 325.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.2181,  0.2190,  0.2162,  0.2013,  0.1946,  0.1942,  0.1840,  0.2412,\n",
      "          0.1959,  0.2177],\n",
      "        [ 0.5275,  0.6111,  0.5361,  0.5584,  0.5054,  0.4990,  0.5399,  0.5911,\n",
      "          0.5243,  0.5406],\n",
      "        [ 0.3522,  0.4018,  0.3498,  0.3430,  0.3571,  0.3284,  0.3573,  0.3843,\n",
      "          0.3205,  0.3579],\n",
      "        [ 0.1895,  0.1882,  0.2268,  0.1824,  0.1771,  0.1599,  0.1778,  0.1977,\n",
      "          0.1903,  0.1906],\n",
      "        [ 0.5495,  0.6145,  0.5578,  0.5393,  0.5267,  0.5003,  0.5578,  0.5737,\n",
      "          0.5308,  0.5701],\n",
      "        [13.4497, 15.4285, 13.6306, 13.9570, 13.2414, 12.3536, 13.5610, 14.0666,\n",
      "         13.2814, 13.5713],\n",
      "        [ 3.7275,  4.2907,  3.7836,  3.8651,  3.6645,  3.4260,  3.7538,  3.9003,\n",
      "          3.6646,  3.7598],\n",
      "        [ 0.2034,  0.2037,  0.2021,  0.2008,  0.1866,  0.1649,  0.1731,  0.2006,\n",
      "          0.2087,  0.2046],\n",
      "        [ 3.7379,  4.2806,  3.7946,  3.8787,  3.6772,  3.4127,  3.7691,  3.8993,\n",
      "          3.6723,  3.7864],\n",
      "        [33.9085, 38.7945, 34.3369, 35.1824, 33.3872, 31.1380, 34.1972, 35.4062,\n",
      "         33.4336, 34.2106]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    print('*' * 100)\n",
    "    print(network[-1].weights[:10])\n",
    "        \n",
    "    for x_batch,y_batch in iterate_minibatches(X_train, y_train, batchsize=32, shuffle=True):\n",
    "        \n",
    "        W_grads, b_grads = train(network, x_batch, y_batch)\n",
    "        layer    = 0\n",
    "        \n",
    "        for l in range(2, len(network), 2):\n",
    "            network[l].backward(W_grads[layer], b_grads[layer])\n",
    "            layer += 1\n",
    "    \n",
    "    print()\n",
    "    print(network[-1].weights[:10])\n",
    "        \n",
    "    train_log.append(np.mean(predict(network, X_train) == y_train))\n",
    "    val_log.append(np.mean(predict(network, X_val) == y_val))\n",
    "    \n",
    "#     clear_output()\n",
    "#     print(\"Epoch\",epoch)\n",
    "#     print(\"Train accuracy:\",train_log[-1])\n",
    "#     print(\"Val accuracy:\",val_log[-1])\n",
    "#     plt.plot(train_log,label='train accuracy')\n",
    "#     plt.plot(val_log,label='val accuracy')\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1064]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1064, 0.1064]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What should you see:__ `train accuracy` should increase to near-100%. Val accuracy will also increase, allbeit to a smaller value.\n",
    "\n",
    "__What else to try:__ You can try implementing different nonlinearities, dropout or composing neural network of more layers. See how this affects training speed, overfitting & final quality.\n",
    "\n",
    "Good hunting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and yes, it's perfectly legal to reuse your code from this seminar in homework01."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
